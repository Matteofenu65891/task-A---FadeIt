This study contributed to the design and development of intelligent systems for the structured representation of fallacious arguments employed within social networks, through participation in sub-task A proposed by EVALITA as part of the FadeIT shared task: identifying fallacies expressed in Italian social media posts. These systems aim to counteract the manipulation of public opinion and the spread of disinformation on sensitive topics in 2025, such as climate change, immigration, and public health.

# First Approach - Large Language Models Optimised through RAG and Dynamic Few-Shot Prompting

For the first approach to the fallacy identification problem, we chose to employ a prompt enriched with examples using the Retrieval Augmented Generation (RAG) technique applied to a vector database containing the training dataset. The RAG technique is used to retrieve information from an external database in order to enhance the quality of responses generated by the model.

The entire system was developed with the aid of the agentic orchestration library by [DataPizza](https://datapizza.tech/en/ai-framework/). DataPizza is an Italian open-source project developed to address the limitations of existing traditional agentic frameworks. Its strengths include minimal abstraction, a debugging-oriented workflow, maximum flexibility, and customisation through the use of components that can be tailored to developers' requirements.

As with a traditional vanilla RAG system, the post classification system is composed of a **retriever**, responsible for retrieving information from the external memory source, and a **fallacy generator** instructed via prompt. For more details, see [AI Engineering - O'Reilly](https://www.oreilly.com/library/view/ai-engineering/9781098166298/).

---

## Retriever

The underlying idea is to use the post to be classified as a search query on the vector database to retrieve examples of similar posts and their corresponding classifications.

For implementation, the advanced open-source vector similarity search technology from **Qdrant** was employed. It offers a wide range of functionalities, including the ability to implement vector databases and similarity search algorithms.

### Collection Configuration

| Parameter | Value |
|-----------|-------|
| **Embedding model** | `text-embedding-3-small` (OpenAI) |
| **Dimension** | 1536 |
| **Format** | Dense vectors |
| **Distance** | Cosine measure |

### Ingestion Pipeline

The first step in development is represented by the ingestion pipeline. During this phase, each post belonging to the training set was:

1. Pre-processed
2. Transformed into embeddings
3. Saved within the collection on Qdrant

Along with the embeddings, for each element, the following metadata were stored:
- Features extracted during pre-processing
- Fallacy labels assigned by annotators A and B
- Token-level classification from the `.conll` file

### Retrieval Phase

The post to be classified is converted into vector format and the **top five most similar examples** are retrieved using cosine measure.

---

## Generator

The model family used in this phase is **OpenAI**. Specifically, tests were conducted on `GPT-4.1` and `GPT-5`.

### Prompt Structure

The prompt contains all the instructions necessary to train the model and is composed of the following elements:

1. **Problem definition**

2. **Description of the fallacy ontology**: for each fallacy, a textual description is provided in order to give the model greater context.

3. **Output definition**: The expected output is a JSON containing a list of Prediction objects (`sub-text`, `fallacy`, `confidence`). During the post-processing phase, predictions with low confidence are discarded.

4. **Suggestions to avoid errors**: certain erroneous behaviours were identified during the development phase. Specific instructions were inserted to circumvent such issues, whilst avoiding leading the model into overfitting with overly specific indications.

5. **List of similar examples**: cosine similarity was used as the measure for identifying similar elements. The post to be classified is transformed into embeddings and the three most similar elements are identified. These elements, together with their respective classifications, are provided to the model within the prompt to guide it towards correct classification. In addition to these elements, the features extracted during the feature extraction phase are also included in the prompt. This was done to simplify the model's reasoning and guide it in establishing relationships between the features of the post to be classified and those of the posts suggested as similar examples. A possible future development for improving the system is represented by the use of features for retrieving similar examples, through their conversion into embeddings and the combination with the embeddings of the various posts.

6. **Features of the post to be classified**: using the feature extraction algorithm described above, the features of the post to be classified were extracted and included in the prompt as additional information.

---

## Experiments

Tests were conducted on a **Mac Mini M4**, using the models via the OpenAI APIs.

During the system evaluation phase, two different versions were analyzed:

- **Simplified version**: a simplified version of the output object returned by the model, without confidence scores and containing only the list of fallacies for each similar example included in the prompt.

- **Final version**: characterized by the use of confidence scores for each prediction, in order to assess how reliable the model considers a given prediction. Furthermore, this version also includes span-level classification (extracted from the `.conll` file) to show, for each example, the specific portions in which the fallacies in the training set were identified by the annotators.

### Results

| Model | Precision | Recall | F1-Score |
|-------|-----------|--------|----------|
| GPT simplified version | 0.54 | 0.50 | 0.52 |
| GPT final version | 0.61 | 0.56 | 0.56 |